
# Customer Churn Prediction

## Project Overview
This project focuses on predicting customer churn using a machine learning approach. Customer churn refers to the loss of customers, and predicting churn can help banks and businesses take proactive measures to retain customers. In this project, we use machine learning models like Random Forest and Logistic Regression to predict whether a customer is likely to churn based on their demographic and financial information.

### Tools & Techniques
- **Machine Learning Models**: Random Forest, Logistic Regression
- **Python Libraries**: pandas, scikit-learn, seaborn, matplotlib, logging, pytest
- **Visualizations**: Customer distributions, correlation heatmaps
- **Data Processing**: Categorical encoding, feature engineering

---

## Table of Contents
1. [Project Overview](#project-overview)
2. [Project Structure](#project-structure)
3. [Installation](#installation)
4. [How to Use](#how-to-use)
5. [Project Workflow](#project-workflow)
6. [Testing](#testing)
7. [Results](#results)
8. [Contributing](#contributing)
9. [License](#license)

---

## Project Structure
```
├── data                          # Raw data and processed data files
│   ├── bank_data.csv             # Dataset used for training and testing
├── images                        # Visualizations generated during EDA
│   ├── churn_distribution.png    
│   ├── customer_age_distribution.png
│   ├── marital_status_distribution.png
│   ├── heatmap.png
├── logs                          # Log files generated by the model and tests
│   └── churn_library.log
├── models                        # Trained machine learning models
│   ├── rfc_model.pkl             # Random Forest model
│   ├── logistic_model.pkl        # Logistic Regression model
├── churn_library_.py             # Main code file with all ML functions
├── churn_script_logging_and_tests.py  # Script for testing and logging
├── README.md                     # Documentation of the project
└── requirements.txt              # Python dependencies for the project
```

---

## Installation

### Prerequisites:
- Python 3.8+
- Recommended: Create a virtual environment

### Steps:
1. **Clone the repository**:
   ```bash
   git clone https://github.com/EsraaKamel11/churn-prediction.git
   ```

2. **Navigate to the project directory**:
   ```bash
   cd churn-prediction
   ```

3. **Install the required dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

The `requirements.txt` file includes:
- pandas
- scikit-learn
- seaborn
- matplotlib
- logging

---

## How to Use

### Running the Project
1. **Data Import**:
   Run the script to import the data and preprocess it:
   ```bash
   python churn_library_solution.py
   ```

2. **Perform EDA**:
   After importing, the script will generate and save visualizations in the `images` folder. 

3. **Feature Engineering**:
   Perform feature engineering to prepare data for model training.

4. **Train Models**:
   Train the models (Random Forest, Logistic Regression) and save them in the `models` folder.

5. **Testing**:
   Run the testing script:
   ```bash
   python churn_script_logging_and_tests.py
   ```
   This will verify the performance of all the functions, and logs can be found in the `logs/churn_library.log` file.

---

## Project Workflow

1. **Data Import**: The `import_data()` function reads the dataset from `data/bank_data.csv` and returns a pandas DataFrame.
2. **Exploratory Data Analysis (EDA)**: The `perform_eda()` function generates several visualizations to understand the data distribution and correlations. The visualizations are saved in the `images/eda` folder.
3. **Categorical Encoding**: The `encoder_helper()` function encodes categorical columns into numerical values that are more suitable for machine learning models.
4. **Feature Engineering**: The `perform_feature_engineering()` function splits the data into training and testing sets, returning feature matrices and target labels for training the models.
5. **Model Training**: The `train_models()` function trains a Random Forest and Logistic Regression model. Both models are saved in the `models` folder as `.pkl` files.

---

## Testing

The project includes unit tests to verify the functionality of each module.

### Running Tests:
You can run the test script to check the functionality of the codebase:
```bash
python churn_script_logging_and_tests.py
```

Logs are stored in `logs/churn_library.log`. The tests cover:
- **Data Import**: Checks that the data is successfully loaded and has rows and columns.
- **EDA**: Ensures all necessary visualizations are generated and saved.
- **Categorical Encoding**: Validates that the categorical columns are properly encoded.
- **Feature Engineering**: Confirms that the train/test data splits are correct.
- **Model Training**: Verifies that the trained models are successfully saved.

---

## Results

After training the models, the performance was evaluated based on precision, recall, and F1-score.

### Model Performance:
- **Random Forest Model**:
   - Precision: 0.84
   - Recall: 0.78
   - F1-Score: 0.81
- **Logistic Regression Model**:
   - Precision: 0.80
   - Recall: 0.75
   - F1-Score: 0.77

These results can be improved by further tuning the hyperparameters or trying additional feature engineering techniques.

---

## Contributing

We welcome contributions from the community. To contribute, please follow these steps:

1. Fork the repository.
2. Create a new branch (`feature/your-feature-name`).
3. Make your changes and commit them.
4. Push your changes to your branch.
5. Submit a pull request with a detailed description of the changes.

---

## License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.




